package feature_generation;

import java.io.File;
import java.io.FileInputStream;
import java.io.ObjectInputStream;
import java.util.ArrayList;
import java.util.regex.Pattern;
import cc.mallet.pipe.CharSequence2TokenSequence;
import cc.mallet.pipe.CharSequenceLowercase;
import cc.mallet.pipe.SerialPipes;
import cc.mallet.pipe.TokenSequence2FeatureSequence;
import cc.mallet.pipe.TokenSequenceRemoveStopwords;
import cc.mallet.topics.ParallelTopicModel;
import cc.mallet.topics.TopicInferencer;
import cc.mallet.types.Instance;
import cc.mallet.types.InstanceList;

public class inferTopicModel {
	public static ParallelTopicModel model = null;
	public static InstanceList instances=null;	
	public inferTopicModel(String modelName) {
		// Begin by importing documents from text to feature sequences
		ArrayList pipeList = new ArrayList();
		// Pipes: lowercase, tokenize, remove stopwords, map to features
		pipeList.add(new CharSequenceLowercase());
		pipeList.add(new CharSequence2TokenSequence(Pattern.compile("\\p{L}[\\p{L}\\p{P}]+\\p{L}")));
		pipeList.add(new TokenSequenceRemoveStopwords(new File("C:\\Users\\ydalal\\Desktop\\yelp\\tools\\mallet-2.0.7\\stoplists\\en.txt"), "UTF-8", false, false, false));
		pipeList.add(new TokenSequence2FeatureSequence());
		instances = new InstanceList(new SerialPipes(pipeList));
		try {			
			FileInputStream in = new FileInputStream("C:\\Users\\ydalal\\Desktop\\yelp\\"+modelName);
			ObjectInputStream ois = new ObjectInputStream(in);			
			model= (ParallelTopicModel) (ois.readObject());			
		} catch (Exception e) {
			System.out.println("Problem serializing: " + e);
		}
		System.out.println("Topic Model is read.");
	}

	public double[] getTopicDitribution(String text) {
		Instance ins=new Instance(text,0,0,0);
		instances.addThruPipe(ins);
		TopicInferencer inferencer = model.getInferencer();
		double results[]=inferencer.getSampledDistribution(instances.get(0), 10, 1, 5);
		instances.remove(0);
		return results;
	}
}

